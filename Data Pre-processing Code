PIXEL_resolution = 20


# Tensorflow and tf.Keras APIs 
import tensorflow as tf 
from tensorflow import keras
print(tf.__version__)

# Supplementing/ helper Libraries 
import numpy as np 
import matplotlib.pyplot as plt 
import glob, os 
import re 
import math

# Python Image Library 
import PIL 
from PIL import Image

!git clone https://github.com/Tim-R413/Cover-Crop-Classification.git

# define a function that crops each full image into 3 seperate size equivalent images  
def image_division (file_path, photo_size):
  full_img = Image.open (file_path) #.convert('L')
  
   # Make aspect ratio as 1:1, by applying image crop. this converts the images into sqaures
  Width, Height = full_img.size
  if Width != Height:
                m_min_d = min(Width, Height)
                full_img = full_img.crop((0, 0, m_min_d, m_min_d))
  
  # Splits the square image into 5 individual images, each cropped to 1/9 the size of the original image 
  DF = m_min_d
  Dim_Min = math.floor(DF / 3 )
  mini_img_a = full_img.crop((0, 0, Dim_Min, Dim_Min))
  mini_img_b = full_img.crop((Dim_Min, Dim_Min, 2*Dim_Min, 2*Dim_Min))
  mini_img_c = full_img.crop((2*Dim_Min, 2*Dim_Min, 3*Dim_Min, 3*Dim_Min))  
  mini_img_d = full_img.crop((Dim_Min*2, 0, DF, Dim_Min))
  mini_img_e = full_img.crop((0, Dim_Min*2, Dim_Min, DF ))
  
   # Scale the image to the requested max photo size by Anti-alias sampling.
  mini_img_a.thumbnail(photo_size, PIL.Image.ANTIALIAS)
  mini_img_b.thumbnail(photo_size, PIL.Image.ANTIALIAS)
  mini_img_c.thumbnail(photo_size, PIL.Image.ANTIALIAS)
  mini_img_d.thumbnail(photo_size, PIL.Image.ANTIALIAS)
  mini_img_e.thumbnail(photo_size, PIL.Image.ANTIALIAS)
  
  # returns each individual image as its own Numpy array
  return np.asarray(mini_img_a), np.asarray(mini_img_b), np.asarray(mini_img_c), np.asarray(mini_img_d), np.asarray(mini_img_e) 
  

# define a function that maximizes the number of elemaets in a dataset by adding the cropped and scaled smaller images as their own peice of data 
def maximize_image_dataset (dir_path, photo_size):
  images = []
  labels=[]
  os.chdir(dir_path)
  
      # analyzes each image file in the designated folder and uses th eimage_division function to extract 5 seperate images from that larger image
  for file in glob.glob("*.JPG"):
    
            img_A, img_B, img_C, img_D, img_E= image_division (file, photo_size)
            img_set = [img_A, img_B, img_C, img_D, img_E]
            how_many = len(img_set)
          
        # appends each mini image to the 'images' dataset and appends its respecting index classification label to the 'label' dataset
        # images and labels are appended together so the index is kept consistent between the two datasets.  
            if re.match('Canola*', file):
                 for i in range (0,how_many):
                    images.append(img_set[i])
                    labels.append(0)
                               
            elif re.match('Clover*', file):
                 for i in range (0,how_many):
                       images.append(img_set[i])
                       labels.append(1)
                    
            elif re.match('Triticale*', file):
                 for i in range (0,how_many):
                        images.append(img_set[i])
                        labels.append(2)
                    
       # same as above section, was made to account for images with the lowercase '.jpg' extension         
  for file in glob.glob("*.jpg"):
    
                img_A, img_B, img_C, img_D, img_E= image_division (file, photo_size)
                img_set = [img_A, img_B, img_C, img_D, img_E]
                how_many = len(img_set)
          
                if re.match('Canola*', file):
                  for i in range (0,how_many):
                    images.append(img_set[i])
                    labels.append(0)
                               
                elif re.match('Clover*', file):
                     for i in range (0,how_many):
                       images.append(img_set[i])
                       labels.append(1)
                    
                elif re.match('Triticale*', file):
                     for i in range (0,how_many):
                       images.append(img_set[i])
                       labels.append(2)
                
  return (np.asarray(images), np.asarray(labels))

# Define a function that shuffles np arrays in unison to keep image and label index consistent:
def unison_shuffled_copies(I, L):
    assert len(I) == len(L)
    p = np.random.permutation(len(I))
    return I[p], L[p]

# image pixel resolution used to train and tset model
a=PIXEL_resolution
photo_size= a, a
%cd /content

# speciescategories or labels are indexed as following: 
#Canola:0 
#Clover:1 
#Triticale:2 

CATEGORIES = ['Canola', 'Clover', 'Triticale']
category_to_index = dict((name, index) for index,name in enumerate (CATEGORIES))
category_to_index


## load training and test data into numpy aarrays by executing these functions: directory path is changed back to root before each function is executed:
%cd /content
(train_images, train_labels) = maximize_image_dataset('Cover-Crop-Classification/TRAINING IMAGES',photo_size)
%cd /content
(test_images, test_labels) = maximize_image_dataset('Cover-Crop-Classification/TESTING IMAGES',photo_size)

print('Original order of images: \n' ,  train_labels)
train_images, train_labels = unison_shuffled_copies(train_images, train_labels)
print ()
print('Shuffled order of images: \n' , train_labels)

## normalize the data
train_images=train_images / 255.0
test_images= test_images / 255.0
